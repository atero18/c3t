---
title: "Introduction à c3t"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Introduction à c3t}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup, message=FALSE, warning=FALSE}
library(c3t)
library(dplyr)
```

L'objectif de ce tutoriel est d'introduire quelques unes des principales fonctions du packages `c3t`.

Commençons par créer une grille factice de taille 4L par 5 qui servira d'exemple pour l'utilisation des différentes fonctions. On peut via la fonction `gen_grid` choisir le nombre d'individus présents sur la grille, si certaines cases doivent être vides et si certaines doivent être plus peuplées que les autres (être des métropoles).

Un contexte sera généra pour chaque individu. Le nombre de variables quantatitatives et qualitatives peut être choisi. Ici on choisit de prendre 2 variables normales centrées réduites.

```{r grid_creation}
set.seed(123L)
x <- 4L
y <- 5L
nbIndividuals <- 100L
nbCasesVides <- 3L
nbMetropolises <- 2L
nbVariablesQuant <- 2L
grille <- gen_grid(x, y, nbIndividuals = nbIndividuals,
                   nbMinEmptyZones = nbCasesVides,
                   nbMetropolises = nbMetropolises,
                   nbQuantitatives = nbVariablesQuant)

data <- grille$context
individus <- grille$repartition$nbIndividuals
contiguite <- grille$contiguity
```

# Régionalisation Ascendante Hiérarchique (RAH)

Dans l'optique de trouver une solution faisable à un problème de régionalisation avec éventuelle contrainte de taille min / et ou max, la fonction `AHR` peut être utilisée. Celle-ci permet d'appliquer un algorithme de Classification Ascendante Hiérarchique modifié afin de respecter les contraintes de contiguïté et taille maximale. Cette fonction va appliquer une ou plusieurs itérations de CAH en fonction des paramétrisations données par l'utilisateur.

Plusieurs paramètres sont disponibles. Pour plus de détails voir `help("AHR")`. Comme pour la CAH classique la fonction prend une distance de liaison (*linkage*). Plusieurs distances sont déjà implémentées dans le *package*, et sont visibles via l'appel suivant :

```{r available_linkages}
available_linkages()
```

Une distance de liaison peut également être proposée par l'utilisateur sous la forme d'une fonction prenant en argument une matrice de distances entre les éléments d'un premier cluster et les éléments d'un autre.

Plusieurs distances de liaison peut être indiquées.

## Contrainte de fusion

Lorsqu'il y a une contrainte de taille min, l'algorithme n'assure pas que celle-ci sera vérifiée contrairement aux autres contraintes. Des paramètres permettent de perturber le parcours de l'arbre afin de faciliter la vérification.

`fusionConstraint` indique s'il faut appliquer une contrainte sur le choix de la fusion et si oui laquelle. Les possibilités implémentées sont les suivantes :

```{r available_fusion_constraints}
available_fusion_constraints()
```

`NA` signifiant qu'aucune contrainte n'est ajoutée.

`fusionConstraintMode` définit comment la contrainte de fusion (si elle existe) doit être appliquée.

```{r available_fusion_modes}
available_fusion_modes()
```

Plusieurs contraintes et modes de fusions peuvent être demandées.

## Situation initiale

Plutôt que de démarrer du bas de l'arbre, c'est-à-dire de la partition triviale (1 élément = 1 cluster), il est possible de démarrer de plus profond et peut-être d'obtenir de meilleur résultat d'un point de vue global ou du point de vue du respect de l'éventuelle contrainte de taille minimale.

L'utilisateur peut choisir s'il souhaite ne démarrer que du bas de l'arbre (de manière classique) ou également essayer de démarrer à partir d'une ou plusieurs partitions initiales générées aléatoirement. C'est ce que permet le paramètre `nbTries`, indiquant le nombre de situations initiales à tester, dont la classique.`propFusionsInit` indique à quel point les partitions obtenues aléatoirement doivent être récupérées profondément dans l'arbre.

## Critères

Un ou plusieurs critères de classification peuvent être calculés sur les différentes solutions faisables, si elles existent. Plusieurs critères sont disponibles :

```{r available_criteria}
available_criteria()
```

Le critère du score de silhouette n'est disponible que si le package `cluster` est installé.

Pour cet exemple nous choisissons le critère "CHI", c'est-à-dire l'indice de Calinski-Harabasz. Celui-ci nécessite qu'un contexte soit donné et que toutes ses variables soient quantitatives.

```{r set_criterion}
critere <- "CHI"
```

## Application

Appliquons l'algorithme sur nous données. Pour cet exemple nous fixons deux contraintes de taille non-triviale (i.e. qui ne sont pas systématiquement vérifiées) et utilisons la distance euclidienne.

```{r set_constraints}
m <- 5.0
M <- 40.0
```

```{r set_distance}
d <- "euclidean"
```

L'algorithme utilise de l'aléatoire pour la génération de partitions initiales et éventuellement l'application de contraintes de fusion. Nous fixons donc préalablement une graine aléatoire.

```{r AHR}
set.seed(123L)
resRAH <- AHR(contiguity = contiguite,
              d = d, data = data,
              sizes = individus,
              m = m, M = M,
              linkages = "saut_min",
              criteria = critere,
              fusionConstraints = available_fusion_constraints(),
              fusionConstraintModes = available_fusion_modes(),
              parallel = FALSE)
```

La fonction renvoie une liste de 3 `tibble`. Les solutions faisables sont contenues dans `results` :

```{r print_res_AHR}
resRAH$results %>%
  select(nbClusters, partition, CHI) %>%
  head()
```

38 solutions faisables distinctes ont été obtenues.

La solution en elle-même se trouve dans la colonne `partition`. Voici la solution faisable qui offre le meilleur indice de Calinski-Harabasz parmi celles trouvées :

```{r print_first_feasible_solution}
regionalisation <- resRAH$results$partition[[1L]]
regionalisation
```

Celle-ci vérifie bien les contraintes de contiguïté et de taille :

```{r confirm_feasibility_AHR}
is_feasible_solution(regionalisation, contiguite,
                     individus, m, M)
```

# Amélioration de la solution faisable

Une solution faisable ayant été obtenue, on souhaite l'améliorer au regard d'un certain critère tout en préservant les contraintes. C'est ce que permet de faire la fonction `enhance_feasible`.

En conservant notre critère précédent (Calinski-Harabasz), on regarde si celui-ci peut être amélioré. On regarde également si le critère d'optimisation locale ("AHC") permet d'améliorer l'ICH. Le critère "AHC" nécessite une distance de liaison. On propose d'utiliser les distances de saut minimal et maximal.

```{r set_enhancement_criteria}
criteresAmelioration <- c("AHC", "CHI")
```

```{r enchancement}
set.seed(123L)
resEnhance <- enhance_feasible(regionalisation,
                               contiguity = contiguite,
                               d = d, data = data,
                               sizes = individus,
                               m = m, M = M,
                               enhanceCriteria = criteresAmelioration,
                               linkages = c("single", "complete"),
                               parallel = FALSE,
                               verbose = TRUE)

resEnhance$results %>% select(-tempsCalcul_mins)
```

L'optimisation sous l'ICH permet d'augmenter cet indice de 0,1 , soit une amélioration d'environ 4%. La solution proposée est bien une solution faisable :

```{r print_enhancement}
partitionCHI <- resEnhance$results$regionalisationOpti[[3L]]
is_feasible_solution(partitionCHI,
                     contiguite,
                     individus, m, M)
```

# Régularisation

Supposons que l'algorithme `AHR` n'ait pas pu fournir une solution faisable (ce qui ne peut être le cas que s'il y a une contrainte de taille minimale). La fonction `resolve_unfeasible` va essayer de fournir une solution faisable à partir d'une solution qui vérifie la contrainte de contiguïté mais pas forcément les contraintes de taille.

Prenons par exemple la partition suivante :

```{r create_unfeasible_solution}
regInfaisable <-
  c(1L, 2L, 3L, 2L, 2L, 2L, 2L, 2L, 2L, 4L,
    4L, 2L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L)
```

Celle-ci est composée de 4L clusters. On peut vérifier que tous ses clusters sont bien des régions, mais qu'elle ne vérifie pas les contraintes de tailles fixées précédemment. Le premier cluster est trop petit et le quatrième trop grand.

```{r confirm_unfeasible}
is_regionalisation(regInfaisable, contiguite)
```

```{r clusters_sizes_unfeasible}
clusters_sizes(regInfaisable, individus)
```

`resolve_unfeasible` va à partir de de régionalisation proposer une solution faisable, en augmentant la taille du premier cluster et en baissant la taille du dernier.

```{r resolve_unfeasible}
set.seed(123L)
resolution <- resolve_unfeasible(contiguity = contiguite,
                                 sizes = individus,
                                 data = data,
                                 d = d, m = m, M = M,
                                 regionalisation = regInfaisable,
                                 verbose = TRUE)

resolution
```

La fonction a obtenu une solution faisable en réalisant six transferts d'éléments. Tous les contraintes sont désormais respectées. En particulier, la solution est bien une régionalisation :

```{r confirm_resolve}
is_regionalisation(resolution$regionalisation, contiguite)
```
